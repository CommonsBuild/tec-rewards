{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448cc226",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_files\": {\n",
    "        \"praise_data\": \"./praise.csv\",\n",
    "        \"rewardboard_list\": \"./rewardboard.csv\"\n",
    "      },\n",
    "      \"total_tokens_allocated\": 1000,\n",
    "      \"payout_token\": {\n",
    "        \"token_name\": \"wxDAI\",\n",
    "        \"token_address\": \"0xe91D153E0b41518A2Ce8Dd3D7944Fa863463a97d\"\n",
    "      },\n",
    "      \"token_reward_percentages\": {\n",
    "        \"contributor_rewards\": 0.871067,\n",
    "        \"quantifier_rewards\": 0.090324,\n",
    "        \"rewardboard_rewards\": 0.038608,\n",
    "        \"_comment\": \"These percentages are tweaked so a regular praise+sourcecred allocation amounts to 7% of total rewards to quantfiers and 3% to the rewardboard.\"\n",
    "      },\n",
    "      \"quantification_settings\": {\n",
    "        \"number_of_quantifiers_per_praise_receiver\": 3,\n",
    "        \"praise_quantify_allowed_values\": [\n",
    "          0, 1, 3, 5, 8, 13, 21, 34, 55, 89, 144\n",
    "        ],\n",
    "        \"praise_quantify_receiver_prseudonyms\": False,\n",
    "        \"praise_quantify_duplicate_praise_valuation\": 0.1\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-image",
   "metadata": {},
   "source": [
    "# Rewards Analytics and Distribution Dashboard\n",
    "This goal of this notebook is to offer an easy way to process the outputs of the praise and sourcecred reward systems, perform an analysis of the results and calculate the token reward distribution. It uses mock data and should be considered a work-in-progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-cheat",
   "metadata": {},
   "source": [
    "### Imports\n",
    "First, we import the relevant libraries, get the Data and set how many tokens we want to distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-unemployment",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f6d12",
   "metadata": {},
   "source": [
    "Now that we have selected the files, we can import them for processing. We can also set the total amount of tokens we want to distribute this period. We also set the name we want our output file to have.\n",
    "\n",
    "Tip: Now that the file paths are set, you can safely click on \"Cell > Run all below\" from here on the menu bar to execute everything :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-encyclopedia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Parameters\n",
    "\n",
    "Set the total amount of tokens we want to distribute this period. We also set the name we want our output file to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a698c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAISE_DATA_PATH = input_files[\"praise_data\"]\n",
    "REWARD_BOARD_ADDRESSES_PATH = input_files[\"rewardboard_list\"]\n",
    "\n",
    "praise_data = pd.read_csv(PRAISE_DATA_PATH)\n",
    "\n",
    "rewardboard_addresses = pd.read_csv(REWARD_BOARD_ADDRESSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-monday",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE = math.trunc( float(total_tokens_allocated) * token_reward_percentages[\"contributor_rewards\"]*1000000) / 1000000\n",
    "#NUMBER_OF_SOURCECRED_REWARD_TOKENS_TO_DISTRIBUTE = 1950\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS = math.trunc(  float(total_tokens_allocated) * token_reward_percentages[\"quantifier_rewards\"]*1000000) / 1000000\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD = math.trunc(  float(total_tokens_allocated) * token_reward_percentages[\"rewardboard_rewards\"]*1000000) / 1000000\n",
    "NUMBER_OF_QUANTIFIERS_PER_PRAISE = params[\"quantification_settings\"][\"number_of_quantifiers_per_praise_receiver\"]\n",
    "\n",
    "OUTPUT_FILENAME = \"rewards_round_01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-organizer",
   "metadata": {},
   "source": [
    "## Reward allocation\n",
    "\n",
    "### Praise\n",
    "\n",
    "This method allocates the praise rewards in a very straightforward way: It adds the value of all dished praised together, and then assigns to each user their % of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-rotation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_praise_rewards(praiseData, tokensToDistribute):\n",
    "    #we discard all we don't need and and calculate the % worth of each praise\n",
    "    #slimData = praiseData[['FROM USER ACCOUNT', 'TO USER ACCOUNT', 'AVG SCORE']].copy()\n",
    "    totalPraisePoints = praiseData['AVG SCORE'].sum()\n",
    "\n",
    "    praiseData['PERCENTAGE'] = praiseData['AVG SCORE']/totalPraisePoints\n",
    "    praiseData['TOKEN TO RECEIVE'] = praiseData['PERCENTAGE'] * tokensToDistribute\n",
    "    return praiseData\n",
    "\n",
    "praise_distribution = calc_praise_rewards(praise_data.copy(), NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "praise_distribution.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-trash",
   "metadata": {},
   "source": [
    "### SourceCred\n",
    "For now Sourcecred does the distribution independently, but if this changed we would calculate the rewards in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-bacteria",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def calc_sourcecred_rewards(sourcecredData, tokensToDistribute):\n",
    "#    #we discard all we don't need and and calculate the % worth of each praise\n",
    "#    slimData = sourcecredData[['IDENTITY', 'AMOUNT']].copy()\n",
    "#    totalGrainPoints = slimData['AMOUNT'].sum()\n",
    "\n",
    "#    slimData['PERCENTAGE'] = slimData['AMOUNT']/totalGrainPoints\n",
    "#    slimData['TOKEN TO RECEIVE'] = slimData['PERCENTAGE'] * tokensToDistribute\n",
    " #   return slimData\n",
    "\n",
    "#sourcecred_distribution = calc_sourcecred_rewards(sourcecred_data.copy(), NUMBER_OF_SOURCECRED_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "#sourcecred_distribution = sourcecred_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-boutique",
   "metadata": {},
   "source": [
    "## Preparing and combining the Datasets\n",
    "\n",
    "Now that we have both distributions, we can combine them into one table.\n",
    "But before that, we need to prepare the data and clean it a bit. We also use the chance to generate a table which shows us how much praise each user received. We'll use it later in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-indonesia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -removes the '#' and following from discord names\n",
    "#  -Some renaming and dropping \n",
    "def prepare_praise(praise_data):\n",
    "\n",
    "    #praise_data['TO USER ACCOUNT'] = (praise_data['TO USER ACCOUNT'].str.split('#', 1, expand=False).str[0]).str.lower()\n",
    "    \n",
    "    praise_data.rename(columns = {'TO USER ACCOUNT':'USER IDENTITY'}, inplace = True)\n",
    "    praise_data.rename(columns = {'TO ETH ADDRESS':'USER ADDRESS'}, inplace = True)\n",
    "    praise_data['USER ADDRESS'].fillna('MISSING USER ADDRESS', inplace=True)\n",
    "    \n",
    "    processed_praise = praise_data[['USER IDENTITY', 'USER ADDRESS', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    praise_by_user = praise_data[['USER IDENTITY', 'USER ADDRESS', 'AVG SCORE', 'PERCENTAGE', 'TOKEN TO RECEIVE']].copy().groupby(['USER IDENTITY', 'USER ADDRESS']).agg('sum').reset_index()\n",
    "    \n",
    "    return processed_praise, praise_by_user\n",
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -Some renaming and dropping \n",
    "#  -changing percentages from 0 - 100 to 0.00-1.00\n",
    "def prepare_sourcecred(sourcecred_data):\n",
    "    \n",
    "    sourcecred_data.rename(columns = {'%':'PERCENTAGE SOURCECRED'}, inplace = True)\n",
    "    sourcecred_data.rename(columns = {'IDENTITY' : 'USER ADDRESS'}, inplace = True)\n",
    "    \n",
    "    sourcecred_data = sourcecred_data[['USER ADDRESS', 'PERCENTAGE SOURCECRED', 'TOKEN TO RECEIVE']]\n",
    "    \n",
    "    return sourcecred_data\n",
    "\n",
    "\n",
    "processed_praise, praise_by_user = prepare_praise(praise_distribution.copy())\n",
    "#processed_sourcecred = prepare_sourcecred(sourcecred_distribution.copy())\n",
    "processed_praise.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-crime",
   "metadata": {},
   "source": [
    "Let's also create a table which will let us focus on the quantifiers. It will show us what value each quantifier gave to each single praise item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-premiere",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#THE NEW CHANGES IN THE DATA FORMAT ARE GOING TO MESS WITH THIS. REVIEW!!!\n",
    "\n",
    "def data_by_quantifier(praise_data):\n",
    "    quant_only = pd.DataFrame()\n",
    "    praise_data.drop(['DATE', 'TO USER ACCOUNT', 'TO ETH ADDRESS', 'FROM USER ACCOUNT', 'FROM ETH ADDRESS', 'REASON', 'SOURCE ID', 'SOURCE NAME', 'AVG SCORE'], axis=1, inplace=True)\n",
    "    num_of_quants = NUMBER_OF_QUANTIFIERS_PER_PRAISE\n",
    "    for i in range(num_of_quants):\n",
    "        q_name =  str( 'QUANTIFIER '+ str(i+1) +' USERNAME' )\n",
    "        q_addr =  str( 'QUANTIFIER '+ str(i+1) +' ETH ADDRESS')\n",
    "        q_value = str('SCORE '+str(i+1) )\n",
    "        buf = praise_data[['ID', q_name , q_addr, q_value ]].copy()\n",
    "    \n",
    "        buf.rename(columns={q_name: 'QUANT_ID', q_addr: 'QUANT_ADDRESS', q_value: 'QUANT_VALUE', 'ID':'PRAISE_ID'}, inplace=True)\n",
    "        #print(buf)\n",
    "        quant_only = quant_only.append(buf.copy(), ignore_index=True)\n",
    "\n",
    "    columnsTitles = ['QUANT_ID', 'QUANT_ADDRESS', 'PRAISE_ID', 'QUANT_VALUE']\n",
    "    quant_only.sort_values(['QUANT_ID', 'PRAISE_ID'], inplace=True)\n",
    "    quant_only =  quant_only.reindex(columns=columnsTitles).reset_index(drop=True)\n",
    "    return quant_only\n",
    "\n",
    "quantifier_rating_table = data_by_quantifier(praise_data.copy())\n",
    "quantifier_rating_table.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83cc4d",
   "metadata": {},
   "source": [
    "Now, we will calculate the rewards for the Quantifiers and the Reward Board. This is fairly straightforward: we distribute the tokens allocated for quantification proportionally to the number of praises quantified, and give all rewardboard members an equal cut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4677f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "quantifier_rewards = pd.DataFrame(quantifier_rating_table[['QUANT_ID','QUANT_ADDRESS']].value_counts().reset_index().copy())\n",
    "quantifier_rewards.rename(columns={ quantifier_rewards.columns[2]: \"NUMBER_OF_PRAISES\" }, inplace = True)\n",
    "\n",
    "total_praise_quantified = quantifier_rewards['NUMBER_OF_PRAISES'].sum()\n",
    "quantifier_rewards['TOKEN TO RECEIVE'] = quantifier_rewards['NUMBER_OF_PRAISES'] / total_praise_quantified  * NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS\n",
    "\n",
    "\n",
    "    \n",
    "quantifier_rewards.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7e71e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rewardboard_rewards = pd.DataFrame(rewardboard_addresses)\n",
    "rewardboard_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD / len(rewardboard_rewards.index)\n",
    "rewardboard_rewards.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b78fa3",
   "metadata": {},
   "source": [
    "Now we can merge them all into one table and save it, ready for distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871efe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def prepare_total_data_chart(praise_rewards, sourcecred_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "def prepare_total_data_chart(praise_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "    \n",
    "    praise_rewards = praise_rewards.copy()[['USER IDENTITY', 'USER ADDRESS', 'TOKEN TO RECEIVE']].rename(columns = {'TOKEN TO RECEIVE':'PRAISE_REWARD'})\n",
    "    praise_rewards['USER ADDRESS'] = praise_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    #sourcecred_rewards = sourcecred_rewards.copy()[['USER ADDRESS', 'TOKEN TO RECEIVE']].rename(columns = {'TOKEN TO RECEIVE':'SOURCECRED_REWARD'})\n",
    "    #sourcecred_rewards['USER ADDRESS'] = sourcecred_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    quantifier_rewards.rename(columns = {'QUANT_ADDRESS':'USER ADDRESS', 'QUANT_ID': 'USER IDENTITY', 'NUMBER_OF_PRAISES': 'NR_OF_PRAISES_QUANTIFIED', 'TOKEN TO RECEIVE':'QUANT_REWARD'}, inplace = True)\n",
    "    quantifier_rewards['USER ADDRESS'] = quantifier_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    rewardboard_rewards.rename(columns = {'ID':'USER ADDRESS', 'TOKEN TO RECEIVE': 'REWARDBOARD_REWARD'}, inplace = True)\n",
    "    rewardboard_rewards['USER ADDRESS'] = rewardboard_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    \n",
    "    final_allocations = pd.merge(rewardboard_rewards, quantifier_rewards , on=['USER ADDRESS','USER ADDRESS'], how='outer')\n",
    "    #final_allocations = pd.merge(final_allocations , sourcecred_rewards, on=['USER ADDRESS','USER ADDRESS'],how='outer')\n",
    "    final_allocations = pd.merge(final_allocations, praise_rewards, left_on=['USER ADDRESS'], right_on=['USER ADDRESS'], how='outer')\n",
    "    \n",
    "    #now we can merge the IDs, replacing any missing values\n",
    "    final_allocations['USER IDENTITY_x']= final_allocations['USER IDENTITY_x'].combine_first(final_allocations['USER IDENTITY_y'])\n",
    "    final_allocations.rename(columns = {'USER IDENTITY_x': 'USER IDENTITY'},  inplace = True)\n",
    "    final_allocations.drop('USER IDENTITY_y', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    final_allocations['USER IDENTITY'].fillna('missing username', inplace = True)\n",
    "    final_allocations.fillna(0, inplace = True)\n",
    "    #final_allocations['TOTAL TO RECEIVE'] = final_allocations['PRAISE_REWARD'] + final_allocations['SOURCECRED_REWARD'] + final_allocations['QUANT_REWARD'] + final_allocations['REWARDBOARD_REWARD']\n",
    "    final_allocations['TOTAL TO RECEIVE'] = final_allocations['PRAISE_REWARD'] + final_allocations['QUANT_REWARD'] + final_allocations['REWARDBOARD_REWARD']\n",
    "   \n",
    "    \n",
    "    final_allocations = final_allocations.sort_values(by= 'TOTAL TO RECEIVE', ascending  = False).reset_index(drop=True)\n",
    "    \n",
    "    #put the columns into the desired order\n",
    "    #final_allocations = final_allocations[['USER IDENTITY', 'USER ADDRESS', 'PRAISE_REWARD', 'SOURCECRED_REWARD', 'QUANT_REWARD','NR_OF_PRAISES_QUANTIFIED', 'REWARDBOARD_REWARD', 'TOTAL TO RECEIVE']]\n",
    "    final_allocations = final_allocations[['USER IDENTITY', 'USER ADDRESS', 'PRAISE_REWARD', 'QUANT_REWARD','NR_OF_PRAISES_QUANTIFIED', 'REWARDBOARD_REWARD', 'TOTAL TO RECEIVE']]\n",
    "    \n",
    "    \n",
    "    return final_allocations\n",
    "\n",
    "#final_token_allocations = prepare_total_data_chart(praise_by_user.copy(), processed_sourcecred.copy(), quantifier_rewards.copy(), rewardboard_rewards.copy())\n",
    "\n",
    "final_token_allocations = prepare_total_data_chart(praise_by_user.copy(), quantifier_rewards.copy(), rewardboard_rewards.copy())\n",
    "final_token_allocations.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4534ac",
   "metadata": {},
   "source": [
    "### \"Glue\" relevant DataFrames to send to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb65ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"final_token_allocations\", final_token_allocations, 'pandas')\n",
    "sb.glue(\"rewardboard_rewards\", rewardboard_rewards, 'pandas')\n",
    "sb.glue(\"quantifier_rewards\", quantifier_rewards, 'pandas')\n",
    "sb.glue(\"quantifier_rating_table\", quantifier_rating_table, 'pandas')\n",
    "\n",
    "sb.glue(\"processed_praise\", processed_praise, 'pandas')\n",
    "sb.glue(\"praise_by_user\", praise_by_user, 'pandas')\n",
    "#sb.glue(\"processed_sourcecred\", processed_sourcecred, 'pandas')\n",
    "\n",
    "#sb.glue(\"sourcecred_distribution\", sourcecred_distribution, 'pandas')\n",
    "sb.glue(\"praise_distribution\", praise_distribution, 'pandas')\n",
    "sb.glue(\"quantifiers_per_praise\", quantification_settings[\"number_of_quantifiers_per_praise_receiver\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3bbca",
   "metadata": {},
   "source": [
    "### Save the distribution files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "#save final allocation to file called \"final_praise_token_allocation.csv\"\n",
    "#save a disperse compatible \"praise_disperse_distribution.csv\" (does it need token address?)\n",
    "#save the extended praise DataFrame (the one with every praise and its weight) \"extended_praise_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_allocation_csv = final_token_allocations.to_csv(index=False)\n",
    "with open('final_praise_token_allocation.csv', 'w') as f:\n",
    "    f.write(final_allocation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_alloc_disperse = final_token_allocations[['USER ADDRESS', 'TOTAL TO RECEIVE']].to_csv(sep=' ', index=False, header=False)\n",
    "with open('praise_disperse_distribution.csv', 'w') as f:\n",
    "    f.write(final_alloc_disperse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_reward_export = praise_distribution.to_csv(index=False)\n",
    "with open('extended_praise_data.csv', 'w') as f:\n",
    "    f.write(praise_reward_export)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
